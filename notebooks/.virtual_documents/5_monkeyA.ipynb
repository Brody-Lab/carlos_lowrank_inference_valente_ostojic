import sys
sys.path.append('../')

from scipy.io import loadmat
from scipy.stats import kurtosis
from glob import glob
import itertools
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import cm
import seaborn as sns
from low_rank_rnns import plotting as plot, stats, helpers, mante, ranktwo, clustering
from low_rank_rnns import data_loader_mante as dlm
from low_rank_rnns.modules import *
import pandas as pd
from sklearn.linear_model import LinearRegression


plot.setup_matplotlib()
plt.rcParams['axes.titlesize'] = 30
plt.rcParams['axes.labelsize'] = 30
plt.rcParams['xtick.labelsize'] = 26
plt.rcParams['ytick.labelsize'] = 26
plt.rcParams['legend.fontsize'] = 22


get_ipython().run_cell_magic("time", "", """bin_width = 5
smoothing_width = 50

dataset = dlm.ManteDataset(monkey='A', bin_width=bin_width, smoothing_width=smoothing_width, cavg=True)""")


# Selecting neurons that have at least one trial for each correct condition
correct_trials = dataset.conditions.correct == 1
good_neurons = ~np.any(dataset.ntrials[correct_trials] == 0, axis=0)
print(good_neurons.sum())
neurons_map_orig = np.where(good_neurons)[0]

# X_all is the data averaged tensor for "valid neurons", X is the same tensor with only non-error trials
X_all = dataset.data_avg[:, :, good_neurons]
X = dataset.data_avg[correct_trials][:, :, good_neurons]
print(X.shape)


n_neurons = X.shape[-1]
print(n_neurons)
nconds = X.shape[0]
print(nconds)
ntime = X.shape[1]
print(ntime)


choice = dataset.conditions[correct_trials]['choice']
context = dataset.conditions[correct_trials]['context']
direction = dataset.conditions[correct_trials]['stim_dir_lvl']
color = dataset.conditions[correct_trials]['stim_col_lvl']


# Denoise data
X_flat = helpers.flatten_trajectory(X)
X_mean = np.mean(X_flat, axis=0)  # Removing the per-neuron mean before denoising
X_flat = (X_flat - X_mean)
pca_std = stats.pca_fit(X_flat, n_components=50)
denoise_mat = pca_std.components_[:12]
X_den = X_flat @ denoise_mat.T @ denoise_mat   # Projection on the top-12 components subspace
X_den_unflat = helpers.unflatten_trajectory(X_den, nconds)
# X_den_tot = X_den_unflat + X_mean   # Re-adding the mean

# np.save('../data/X_den_monkeyA.npy', X_den_unflat)


# Perform linear regression
conditions_regressors = dataset.conditions[correct_trials][['choice', 'stim_dir', 'stim_col', 'context']].to_numpy()
X_den_percond = X_den_unflat.reshape((nconds, -1))
print(conditions_regressors.shape)
print(X_den_percond.shape)
# Linear regression
linmodel = LinearRegression(fit_intercept=True)
linmodel = linmodel.fit(conditions_regressors, X_den_percond)
betas = linmodel.coef_.T.reshape((4, ntime, -1))
intercepts = linmodel.intercept_.T.reshape((ntime, -1))
betas = np.concatenate([betas, intercepts[np.newaxis, :, :]], axis=0)
print(betas.shape)

# Denoise betas
betas = betas @ denoise_mat.T @ denoise_mat

# Data without the time component
X_cent = X_den_unflat - betas[-1]

mean_abs_act = np.abs(X_cent).mean(axis=(0,1))

# np.save('../data/X_cent_monkeyA.npy', X_cent)
# dataset.conditions.to_csv('../data/conditions_monkeyA.csv')


get_ipython().run_line_magic("matplotlib", " inline")

# print norm of the vectors and identify t_max, define TDR orthogonalized axes
tmaxes = []
labels = ['choice', 'motion', 'color', 'context', 'intercept']
for i in range(5):
    norms = np.linalg.norm(betas[i], axis=1)
    p, = plt.plot(norms, label=labels[i], lw=3)
    tmaxes.append(np.argmax(norms))
    plt.plot([tmaxes[-1]], [norms[tmaxes[-1]]], marker='*', c=p.get_color(), markersize=10)
plt.legend(bbox_to_anchor=(1, .8))
plt.ylabel('norm')
plt.xlabel('time (dt=5ms)')

# Choose timepoints for the axes, orthogonalize
beta_choice = betas[0, tmaxes[0]]
beta_motion = betas[1, tmaxes[1]]
beta_color = betas[2, tmaxes[2]]
beta_context = betas[3, tmaxes[3]]
Bmat = np.vstack([beta_choice, beta_motion, beta_color, beta_context]).T
print(Bmat.shape)
BmatQ, _ = np.linalg.qr(Bmat)
beta_choice = BmatQ[:, 0]
beta_motion = BmatQ[:, 1]
beta_color = BmatQ[:, 2]
beta_context = BmatQ[:, 3]

# np.save('../data/beta_axes_monkeyA.npy', BmatQ)


X_lin = X_cent @ BmatQ @ BmatQ.T  # X_lin is the activity projected on only the 4 beta axes
X_lin.shape
# np.save('../data/X_lin_monkeyA.npy', X_lin)


# Prepare pseudo-inputs
mante.fixation_duration = 0
mante.ctx_only_pre_duration = 350 # changed from 100 to 350 on 05.05 (#22)
mante.stimulus_duration = 650   # adjusted to account for initial state of the network (1st step doesn't count)
mante.delay_duration = 95
mante.decision_duration = 5
mante.deltaT = bin_width
mante.SCALE = 1
mante.SCALE_CTX = 1
mante.setup()

inputs, targets_task, mask_task = mante.generate_mante_data_from_conditions(dataset.conditions[correct_trials]['stim_dir'].to_numpy(),
                                                         dataset.conditions[correct_trials]['stim_col'].to_numpy(),
                                                         context.to_numpy())

hidden_neurons = 0
size = n_neurons + hidden_neurons

coherences = np.unique(dataset.conditions[correct_trials]['stim_dir'].to_numpy())
coherences


hidden_neurons = 0


size = n_neurons + hidden_neurons
net_fr = FullRankRNN(4, size, n_neurons, 0, 0.2, output_non_linearity=(lambda x: x))
net_fr.load_state_dict(torch.load('../models/mante_monkeyA_subspace_22.pt'))


_, traj_fr = net_fr(inputs, return_dynamics=True)
traj_fr = traj_fr.detach().numpy()[:, mante.ctx_only_pre_duration_discrete+1:, :][:, :, :n_neurons]


r2_global_fr = stats.r2_score(X_cent.ravel(), traj_fr.ravel())
print(f'R2 global: {r2_global_fr}')
print(f'R2 per neuron mean: {stats.r2_idneurons(X_cent, traj_fr)}')


r2s = np.array(stats.r2_idneurons(X_cent, traj_fr, return_all=True))
print(f'R2 per neuron median: {np.median(r2s)}')
r2_median_fr = np.median(r2s)


decisions = np.sign((traj_fr @ beta_choice)[:, -1])
acc_fr = (choice.values == -decisions).sum() / 72
print(acc_fr)


sns.boxplot(r2s)
plt.xlim(-1, 1)


sns.scatterplot(X_mean, r2s)
plt.ylim(-1, 1)
plt.axhline(0, c='gray', ls='--')
plt.axhline(1, c='gray', ls='--')
plt.xlabel('mean FR')
plt.ylabel('R2')


# Training a linear readout for the full-rank fitted RNN
net_fr_behav = FullRankRNN(4, size, 1, 0, 0.2, wi_init=net_fr.wi_full, wrec_init=net_fr.wrec,
                           wo_init=torch.from_numpy(beta_choice.reshape((-1, 1))) / size, train_wi=False, 
                           train_si=False, train_wrec=False, train_wo=True)
train(net_fr_behav, inputs, targets_task, mask_task, 20, lr=1e-3, keep_best=True)
loss, acc = mante.test_mante(net_fr_behav, inputs, targets_task, mask_task)
print(acc)


# 348 neurons with an R2 < 0, out of 727 !!
idx_bad = np.where(r2s < 0)[0]
print(len(idx_bad))


# # Trying to get readout and R2 from the network without the poorly fitted neurons:
# # the resulting fit is absolutely catastrophic
# neurons_map_fr = np.setdiff1d(np.arange(size), idx_bad)
# print(size - len(idx_bad))
# net_fr_behav = FullRankRNN(4, size - len(idx_bad), 1, 0, 0.2,
#                      wi_init=net_fr.wi_full[:, neurons_map_fr], wrec_init=net_fr.wrec[neurons_map_fr][:, neurons_map_fr],
#                      wo_init=torch.from_numpy(beta_choice[neurons_map_fr].reshape((-1, 1))) / size,
#                      train_wi=False, train_si=False, train_wrec=False, train_wo=True)

# outp, traj = net_fr_behav(inputs, return_dynamics=True)
# traj = traj.detach().numpy()[:, mante.ctx_only_pre_duration_discrete+1:, :][:, :, :n_neurons]
# r2_global_fr2 = stats.r2_score(X_cent[:, :, neurons_map_fr].ravel(), traj.ravel())
# print(f'R2 global: {r2_global_fr}')
# r2s = np.array(stats.r2_idneurons(X_cent[:, :, neurons_map_fr], traj, return_all=True))
# print(f'R2 per neuron median: {np.median(r2s)}')
# r2_median_fr2 = np.median(r2s)
# print(f'R2 per neuron mean: {np.mean(r2s)}')
# train(net_fr_behav, inputs, targets_task, mask_task, 50, lr=1e-3, keep_best=True)
# loss, acc = mante.test_mante(net_fr_behav, inputs, targets_task, mask_task)
# print(acc)


# sns.boxplot(r2s)
# plt.xlim(-1, 1)


r2s_glob = []
r2s_medians = []
accs = []

ranks = list(range(1, 6))
for rank in ranks:
    net = LowRankRNN(4, size, n_neurons, 0, 0.2, rank=rank, output_non_linearity=(lambda x: x))
    net.load_state_dict(torch.load(f'../models/mante_monkeyA_subspace_rank{rank}_22.pt'))
    _, traj = net(inputs, return_dynamics=True)
    # traj = net.non_linearity(traj)
    traj = traj.detach().numpy()[:, mante.ctx_only_pre_duration_discrete+1:, :][:, :, :n_neurons]
    
    r2s_glob.append(stats.r2_score(X_cent.ravel(), traj.ravel()))
    print(f'Rank {rank}, test R2 global: {r2s_glob[-1]}')
    
    r2s_all = stats.r2_idneurons(X_cent, traj, return_all=True)
    print(f'Rank {rank}, test R2 per neuron mean: {np.mean(r2s_all)}')
    r2s_medians.append(np.median(r2s_all))
    print(f'Rank {rank}, test R2 per neuron median: {r2s_medians[-1]}')
    
    decisions = np.sign((traj @ beta_choice)[:, -1])
    acc = (choice.values == -decisions).sum() / 72
    print(f'Rank {rank}, accuracy: {acc:.2f}')
    accs.append(acc)


plt.figure(figsize=(5.5, 4))
# plt.plot(ranks, r2s_glob, marker='o', label='global', c='tab:blue', lw=3, markersize=9)
plt.plot(ranks, r2s_glob, marker='o', c='tab:blue', label='global $R^2$', lw=4)
plt.plot(ranks, accs, marker='o', c='firebrick', label='accuracy', lw=4)
plt.scatter([6], [r2_global_fr], color='tab:blue', marker='*', s=100)
plt.scatter([6], [acc_fr], color='firebrick', marker='*', s=100)
plt.ylim(0, 1.1)
plt.yticks(np.arange(0, 1.1, 0.25))
plt.gca().set_yticklabels([0, '', '', '', 1])
plt.xticks([1, 2, 3, 4, 5, 6])
plt.gca().set_xticklabels([1, 2, 3, 4, 5, 'full'])
plt.legend(loc='lower right')
plt.xlabel('rank')
plt.ylabel('$R^2$ / accuracy')
plt.axhline(1, ls='--', c='gray')
# plt.savefig('../figures/neurips/r2_monkeyA.pdf', bbox_inches='tight')


rank = 1
net = LowRankRNN(4, size, n_neurons, 0, 0.2, rank=rank, output_non_linearity=(lambda x: x))
net.load_state_dict(torch.load(f'../models/mante_monkeyA_subspace_rank{rank}_22.pt'))
outp, traj = net(inputs, return_dynamics=True)
traj_tot = traj.detach().numpy()[:, :, :n_neurons]
traj = traj.detach().numpy()[:, mante.ctx_only_pre_duration_discrete+1:, :][:, :, :n_neurons]

decisions = np.sign((traj @ beta_choice)[:, -1])
acc = (choice.values == -decisions).sum() / 72
print(acc)


net.svd_reparametrization()


wis = [net.wi_full[i].detach().numpy() for i in range(4)]
ms = [net.m[:, i].detach().numpy() for i in range(rank)]
ns = [net.n[:, i].detach().numpy() for i in range(rank)]


wi1 = net.wi_full[0].detach().numpy()
wi2 = net.wi_full[1].detach().numpy()
wi_ctx1 = net.wi_full[2].detach().numpy()
wi_ctx2 = net.wi_full[3].detach().numpy()
m = net.m.squeeze().detach().numpy()
n = net.n.squeeze().detach().numpy()


m = ms[0]
n = ns[0]


net_behav = LowRankRNN(4, size, 1, 0, 0.2, rank=1, output_non_linearity=(lambda x: x), 
                       wi_init=net.wi_full, m_init=net.m, n_init=net.n, 
                       wo_init=torch.from_numpy(-beta_choice.reshape((-1, 1))),
                       train_wi=False, train_wrec=False, train_si=False, train_wo=True)
train(net_behav, inputs, targets_task, mask_task, 20, lr=1e-1, keep_best=True)


wo = net_behav.wo_full.squeeze().detach().numpy()


mante.psychometric_matrices(net_behav, coherences=coherences)


vecs = [wi1, wi2, wi_ctx1, wi_ctx2, m, n, wo]
betas = [beta_motion, beta_color, beta_context, beta_choice]

mat = helpers.overlap_matrix2(betas, vecs, norm='norm', figsize=(10, 4))
plt.xlabel('Fitted connectivity')
plt.ylabel('TDR axes')
plt.xticks(np.arange(0.5, 7, 1), ['$I^A$', '$I^B$', '$I^{ctxA}$', '$I^{ctxB}$', '$m$', '$n$', '$w$'])
plt.yticks(np.arange(0.5, 4, 1), ['motion', 'color', 'context', 'choice'], rotation='horizontal')
plt.savefig('../figures/neurips/si_monkeyA_tdroverlaps.pdf', bbox_inches='tight')


r2s = np.array(stats.r2_idneurons(X_cent, traj, return_all=True))


# %matplotlib widget
sns.boxplot(r2s)
plt.xlim(-1, 1)


catastrophic = np.where(r2s < -1)[0]
print(catastrophic)
print(len(catastrophic))
print(r2s[catastrophic])


idx_bad = np.where(r2s < 0)[0]
print(idx_bad)
print(len(idx_bad))


conditions_sample = [((direction == 0) & (color == 5) & (context == 1)),
                     ((direction == 5) & (color == 0) & (context == 1)),
                     ((direction == 5) & (color == 0) & (context == -1)),
                     ((direction == 0) & (color == 5) & (context == -1))]
cmap1 = matplotlib.cm.get_cmap('bwr')
cmap2 = matplotlib.cm.get_cmap('PiYG')
colors = ['royalblue', 'seagreen', 'firebrick', 'darkorange']


# conditions_rsample = random.sample(range(nconds), 4)
for i in np.argsort(r2s_all)[:18]:
    print(r2s_all[i])
    for c, k in enumerate(conditions_sample):
        pl, = plt.plot(X_cent[k, :, i].mean(axis=0), c=colors[c], lw=3)
        plt.plot(traj[k, :, i].mean(axis=0), ls='-.', c=pl.get_color(), lw=3)
    plt.title(f'neuron #{neurons_map_orig[i]} (r2={r2s_all[i]:.2f})')
    plt.xlabel('time')
    plt.ylabel('x')
    plt.savefig(f'../figures/neurips/lotsmore/si_monkeyA_neuron{neurons_map_orig[i]}.pdf', bbox_inches='tight')
    plt.show()
    


for i in np.argsort(r2s_all)[::-1][:10]:
    print(r2s_all[i])
    for c, k in enumerate(conditions_sample):
        pl, = plt.plot(X_cent[k, :, i].mean(axis=0), c=colors[c], lw=3)
        plt.plot(traj[k, :, i].mean(axis=0), ls='-.', c=pl.get_color(), lw=3)
    plt.title(f'neuron #{neurons_map_orig[i]} (r2={r2s_all[i]:.2f})')
    plt.xlabel('time')
    plt.ylabel('x')
    plt.savefig(f'../figures/neurips/lotsmore/si_monkeyA_neuron{neurons_map_orig[i]}.pdf', bbox_inches='tight')
    plt.show()


rdm_neurons = np.random.choice(np.arange(size), 4, replace=False)
for i in rdm_neurons:
    print(r2s_all[i])
    for c, k in enumerate(conditions_sample):
        pl, = plt.plot(X_cent[k, :, i].mean(axis=0), c=colors[c], lw=3)
        plt.plot(traj[k, :, i].mean(axis=0), ls='-.', c=pl.get_color(), lw=3)
    plt.title(f'neuron #{neurons_map_orig[i]} (r2={r2s_all[i]:.2f})')
    plt.xlabel('time')
    plt.ylabel('x')
    plt.savefig(f'../figures/neurips/lotsmore/si_monkeyA_neuron{neurons_map_orig[i]}.pdf', bbox_inches='tight')
    plt.show()


# Are poorly fitted neurons irrelevant ?
sns.scatterplot(X_mean, r2s, s=60)
plt.ylim(-1, 1)
plt.axhline(0, c='gray', ls='--')
plt.axhline(1, c='gray', ls='--')
plt.axhline(np.median(r2s), c='indianred', ls='--', lw=3, zorder=0)
plt.xlabel('Mean FR')
plt.ylabel('$R^2$')
# plt.savefig('../figures/neurips/r2_fr.pdf', bbox_inches='tight')


g = sns.JointGrid()
g.fig.set_figwidth(6)
g.fig.set_figheight(4)
sns.scatterplot(x=X_mean, y=r2s, s=60, ax=g.ax_joint, color='royalblue')
sns.boxplot(y=r2s, ax=g.ax_marg_y, saturation=0)
# sns.kdeplot(x=X_mean, ax=g.ax_marg_x)
g.ax_joint.set_xlabel('Mean FR')
g.ax_joint.set_ylabel('$R^2$')
g.ax_joint.axhline(0, c='gray', ls='--')
g.ax_joint.axhline(1, c='gray', ls='--')
g.ax_joint.axhline(np.median(r2s), c='indianred', ls='--', lw=3, zorder=0)
plt.ylim(-1, 1)
plt.savefig('../figures/neurips/r2_fr.pdf', bbox_inches='tight')


# And with the mean deviation to baseline activity
sns.scatterplot(mean_abs_act[r2s> -1], r2s[r2s > -1])
plt.ylim(-1, 1)
plt.axhline(0, c='gray', ls='--')
plt.axhline(1, c='gray', ls='--')
plt.xlabel('Mean activity')
plt.ylabel('R2')
# plt.scatter(-0.1, np.median(r2s), c='indianred', marker='>', s=100)
plt.axhline(np.median(r2s), c='indianred', ls='--', lw=3, zorder=0)


print(catastrophic)
print(X_mean[catastrophic])
print(np.max(X_mean[catastrophic]))


# Removing the neurons with r2 < 0
net_tmp = net_behav.clone()

with torch.no_grad():
    net_tmp.wi[:, idx_bad] = 0
    net_tmp.m[idx_bad] = 0
    net_tmp.n[idx_bad] = 0

loss, acc = mante.test_mante(net_tmp, inputs, targets_task, mask_task)
print(acc)
train(net_tmp, inputs, targets_task, mask_task, 20, lr=1e-1, keep_best=True)
loss, acc = mante.test_mante(net_tmp, inputs, targets_task, mask_task)
print(acc)


# What if we remove other random sets of as many neurons ?
for _ in range(10):
    rndm_sample = np.random.choice(np.arange(size), len(idx_bad))
    net_tmp = net_behav.clone()
    with torch.no_grad():
        net_tmp.wi[:, rndm_sample] = 0
        net_tmp.m[rndm_sample] = 0
        net_tmp.n[rndm_sample] = 0
    loss, acc = mante.test_mante(net_tmp, inputs, targets_task, mask_task)
    print(acc)


cmap = matplotlib.cm.get_cmap('bwr')

conditions = [((direction == 0) & (context == 1)),
              ((direction == 5) & (context == 1))]
colors = [cmap(0), cmap(256)]

ax1 = beta_choice
ax2 = beta_motion

for c in range(len(conditions)):
    plt.plot(X_cent[conditions[c]].mean(axis=0) @ ax1, 
             X_cent[conditions[c]].mean(axis=0) @ ax2, c=colors[c], lw=3)    
    plt.plot(X_cent[conditions[c]].mean(axis=0)[0] @ ax1, 
             X_cent[conditions[c]].mean(axis=0)[0] @ ax2, 
             marker='o', c=colors[c], lw=3)
    plt.plot(traj_tot[conditions[c]].mean(axis=0) @ ax1, 
             traj_tot[conditions[c]].mean(axis=0) @ ax2, 
             c=colors[c], ls='dotted', lw=3)
    plt.plot(traj_tot[conditions[c]].mean(axis=0)[0] @ ax1, 
             traj_tot[conditions[c]].mean(axis=0)[0] @ ax2, 
             marker='o', c=colors[c], ls='dotted', lw=3)
    plt.scatter(traj_tot[conditions[c]].mean(axis=0)[mante.ctx_only_pre_duration_discrete] @ ax1,
                traj_tot[conditions[c]].mean(axis=0)[mante.ctx_only_pre_duration_discrete] @ ax2,
                color=colors[c], marker='^', s=100)
plt.xlabel('choice axis')
plt.ylabel('motion axis')
plt.xticks([])
plt.yticks([])
plt.savefig('../figures/neurips/proj_si1.pdf', bbox_inches='tight')


cmap = matplotlib.cm.get_cmap('PiYG')

conditions = [((color == i) & (context == 1) & (choice == j)) for i in (0, 5) for j in (-1, 1)]
colors = [cmap(0)] * 2 + [cmap(256)] * 2

ax1 = beta_choice
ax2 = beta_color

for c in range(len(conditions)):
    plt.plot(X_cent[conditions[c]].mean(axis=0) @ ax1, 
             X_cent[conditions[c]].mean(axis=0) @ ax2, c=colors[c], lw=3)    
    plt.plot(X_cent[conditions[c]].mean(axis=0)[0] @ ax1, 
             X_cent[conditions[c]].mean(axis=0)[0] @ ax2, 
             marker='o', c=colors[c], lw=3)
    plt.plot(traj_tot[conditions[c]].mean(axis=0) @ ax1, 
             traj_tot[conditions[c]].mean(axis=0) @ ax2, 
             c=colors[c], ls='dotted', lw=3)
    plt.plot(traj_tot[conditions[c]].mean(axis=0)[0] @ ax1, 
             traj_tot[conditions[c]].mean(axis=0)[0] @ ax2, 
             marker='o', c=colors[c], ls='dotted', lw=3)
    plt.scatter(traj_tot[conditions[c]].mean(axis=0)[mante.ctx_only_pre_duration_discrete] @ ax1,
                traj_tot[conditions[c]].mean(axis=0)[mante.ctx_only_pre_duration_discrete] @ ax2,
                color=colors[c], marker='^', s=100)
plt.xlabel('choice axis')
plt.ylabel('color axis')
plt.xticks([])
plt.yticks([])
plt.savefig('../figures/neurips/proj_si2.pdf', bbox_inches='tight')


cmap = matplotlib.cm.get_cmap('bwr')

conditions = [((direction == i) & (context == -1) & (choice == j)) for i in (0, 5) for j in (-1, 1)]
colors = [cmap(0)] * 2 + [cmap(256)] * 2

ax1 = beta_choice
ax2 = beta_motion

for c in range(len(conditions)):
    plt.plot(X_cent[conditions[c]].mean(axis=0) @ ax1,
             X_cent[conditions[c]].mean(axis=0) @ ax2, c=colors[c], lw=3)    
    plt.plot(X_cent[conditions[c]].mean(axis=0)[0] @ ax1, 
             X_cent[conditions[c]].mean(axis=0)[0] @ ax2, 
             marker='o', c=colors[c], lw=3)
    plt.plot(traj_tot[conditions[c]].mean(axis=0) @ ax1, 
             traj_tot[conditions[c]].mean(axis=0) @ ax2, 
             c=colors[c], ls='dotted', lw=3)
    plt.plot(traj_tot[conditions[c]].mean(axis=0)[0] @ ax1, 
             traj_tot[conditions[c]].mean(axis=0)[0] @ ax2, 
             marker='o', c=colors[c], ls='dotted', lw=3)
    plt.scatter(traj_tot[conditions[c]].mean(axis=0)[mante.ctx_only_pre_duration_discrete] @ ax1,
                traj_tot[conditions[c]].mean(axis=0)[mante.ctx_only_pre_duration_discrete] @ ax2,
                color=colors[c], marker='^', s=100)
plt.xlabel('choice axis')
plt.ylabel('motion axis')
plt.xticks([])
plt.yticks([])
plt.savefig('../figures/neurips/proj_si3.pdf', bbox_inches='tight')


cmap = matplotlib.cm.get_cmap('PiYG')

conditions = [((color == i) & (context == -1)) for i in (0, 5)]
colors = [cmap(0), cmap(256)]

ax1 = beta_choice
ax2 = beta_color

for c in range(len(conditions)):
    plt.plot(X_cent[conditions[c]].mean(axis=0) @ ax1,
             X_cent[conditions[c]].mean(axis=0) @ ax2, c=colors[c], lw=3)    
    plt.plot(X_cent[conditions[c]].mean(axis=0)[0] @ ax1, 
             X_cent[conditions[c]].mean(axis=0)[0] @ ax2, 
             marker='o', c=colors[c], lw=3)
    plt.plot(traj_tot[conditions[c]].mean(axis=0) @ ax1, 
             traj_tot[conditions[c]].mean(axis=0) @ ax2, 
             c=colors[c], ls='dotted', lw=3)
    plt.plot(traj_tot[conditions[c]].mean(axis=0)[0] @ ax1, 
             traj_tot[conditions[c]].mean(axis=0)[0] @ ax2, 
             marker='o', c=colors[c], ls='dotted', lw=3)
    plt.scatter(traj_tot[conditions[c]].mean(axis=0)[mante.ctx_only_pre_duration_discrete] @ ax1,
                traj_tot[conditions[c]].mean(axis=0)[mante.ctx_only_pre_duration_discrete] @ ax2,
                color=colors[c], marker='^', s=100)
plt.xlabel('choice axis')
plt.ylabel('color axis')
plt.xticks([])
plt.yticks([])
plt.savefig('../figures/neurips/proj_si4.pdf', bbox_inches='tight')


cmap = matplotlib.cm.get_cmap('PiYG')

conditions = [((choice == i) & (context == j)) for i in (-1, 1) for j in (-1, 1)]
colors = ['peru', 'firebrick', 'peru', 'firebrick']

ax1 = beta_choice
ax2 = beta_context

for c in range(len(conditions)):
    plt.plot(X_cent[conditions[c]].mean(axis=0) @ ax1,
             X_cent[conditions[c]].mean(axis=0) @ ax2, c=colors[c], lw=3)    
    plt.plot(X_cent[conditions[c]].mean(axis=0)[0] @ ax1, 
             X_cent[conditions[c]].mean(axis=0)[0] @ ax2, 
             marker='o', c=colors[c], lw=3)
    plt.plot(traj_tot[conditions[c]].mean(axis=0) @ ax1, 
             traj_tot[conditions[c]].mean(axis=0) @ ax2, 
             c=colors[c], ls='dotted', lw=3)
    plt.plot(traj_tot[conditions[c]].mean(axis=0)[0] @ ax1, 
             traj_tot[conditions[c]].mean(axis=0)[0] @ ax2, 
             marker='o', c=colors[c], ls='dotted', lw=3)
    plt.scatter(traj_tot[conditions[c]].mean(axis=0)[mante.ctx_only_pre_duration_discrete] @ ax1,
                traj_tot[conditions[c]].mean(axis=0)[mante.ctx_only_pre_duration_discrete] @ ax2,
                color=colors[c], marker='^', s=100)
plt.xlabel('choice axis')
plt.ylabel('context axis')
plt.xticks([])
plt.yticks([])
plt.savefig('../figures/neurips/proj_si5.pdf', bbox_inches='tight')


cmap = matplotlib.cm.get_cmap('bwr')

conditions = [((direction == 0) & (context == 1)),
              ((direction == 5) & (context == 1))]
colors = [cmap(0), cmap(256)]

ax1 = m
ax2 = wis[0]

for c in range(len(conditions)):
    plt.plot(X_cent[conditions[c]].mean(axis=0) @ ax1, 
             X_cent[conditions[c]].mean(axis=0) @ ax2, c=colors[c], lw=3)    
    plt.plot(X_cent[conditions[c]].mean(axis=0)[0] @ ax1, 
             X_cent[conditions[c]].mean(axis=0)[0] @ ax2, 
             marker='o', c=colors[c], lw=3)
    plt.plot(traj_tot[conditions[c]].mean(axis=0) @ ax1, 
             traj_tot[conditions[c]].mean(axis=0) @ ax2, 
             c=colors[c], ls='dotted', lw=3)
    plt.plot(traj_tot[conditions[c]].mean(axis=0)[0] @ ax1, 
             traj_tot[conditions[c]].mean(axis=0)[0] @ ax2, 
             marker='o', c=colors[c], ls='dotted', lw=3)
    plt.scatter(traj_tot[conditions[c]].mean(axis=0)[mante.ctx_only_pre_duration_discrete] @ ax1,
                traj_tot[conditions[c]].mean(axis=0)[mante.ctx_only_pre_duration_discrete] @ ax2,
                color=colors[c], marker='^', s=100)
plt.xlabel('$m$')
plt.ylabel('$I_{motion}$')
plt.xticks([])
plt.yticks([])
plt.savefig('../figures/neurips/proj1.pdf', bbox_inches='tight')


cmap = matplotlib.cm.get_cmap('PiYG')

conditions = [((color == i) & (context == 1) & (choice == j)) for i in (0, 5) for j in (-1, 1)]
colors = [cmap(0)] * 2 + [cmap(256)] * 2

ax1 = m
ax2 = wis[1]

for c in range(len(conditions)):
    plt.plot(X_cent[conditions[c]].mean(axis=0) @ ax1, 
             X_cent[conditions[c]].mean(axis=0) @ ax2, c=colors[c], lw=3)    
    plt.plot(X_cent[conditions[c]].mean(axis=0)[0] @ ax1, 
             X_cent[conditions[c]].mean(axis=0)[0] @ ax2, 
             marker='o', c=colors[c], lw=3)
    plt.plot(traj_tot[conditions[c]].mean(axis=0) @ ax1, 
             traj_tot[conditions[c]].mean(axis=0) @ ax2, 
             c=colors[c], ls='dotted', lw=3)
    plt.plot(traj_tot[conditions[c]].mean(axis=0)[0] @ ax1, 
             traj_tot[conditions[c]].mean(axis=0)[0] @ ax2, 
             marker='o', c=colors[c], ls='dotted', lw=3)
    plt.scatter(traj_tot[conditions[c]].mean(axis=0)[mante.ctx_only_pre_duration_discrete] @ ax1,
                traj_tot[conditions[c]].mean(axis=0)[mante.ctx_only_pre_duration_discrete] @ ax2,
                color=colors[c], marker='^', s=100)
plt.xlabel('$m$')
plt.ylabel('$I_{color}$')
plt.xticks([])
plt.yticks([])
plt.savefig('../figures/neurips/proj2.pdf', bbox_inches='tight')


cmap = matplotlib.cm.get_cmap('bwr')

conditions = [((direction == i) & (context == -1) & (choice == j)) for i in (0, 5) for j in (-1, 1)]
colors = [cmap(0)] * 2 + [cmap(256)] * 2

ax1 = m
ax2 = wis[0]

for c in range(len(conditions)):
    plt.plot(X_cent[conditions[c]].mean(axis=0) @ ax1,
             X_cent[conditions[c]].mean(axis=0) @ ax2, c=colors[c], lw=3)    
    plt.plot(X_cent[conditions[c]].mean(axis=0)[0] @ ax1, 
             X_cent[conditions[c]].mean(axis=0)[0] @ ax2, 
             marker='o', c=colors[c], lw=3)
    plt.plot(traj_tot[conditions[c]].mean(axis=0) @ ax1, 
             traj_tot[conditions[c]].mean(axis=0) @ ax2, 
             c=colors[c], ls='dotted', lw=3)
    plt.plot(traj_tot[conditions[c]].mean(axis=0)[0] @ ax1, 
             traj_tot[conditions[c]].mean(axis=0)[0] @ ax2, 
             marker='o', c=colors[c], ls='dotted', lw=3)
    plt.scatter(traj_tot[conditions[c]].mean(axis=0)[mante.ctx_only_pre_duration_discrete] @ ax1,
                traj_tot[conditions[c]].mean(axis=0)[mante.ctx_only_pre_duration_discrete] @ ax2,
                color=colors[c], marker='^', s=100)
plt.xlabel('$m$')
plt.ylabel('$I_{motion}$')
plt.xticks([])
plt.yticks([])
plt.savefig('../figures/neurips/proj3.pdf', bbox_inches='tight')


cmap = matplotlib.cm.get_cmap('PiYG')

conditions = [((color == i) & (context == -1)) for i in (0, 5)]
colors = [cmap(0), cmap(256)]

ax1 = m
ax2 = wis[1]

for c in range(len(conditions)):
    plt.plot(X_cent[conditions[c]].mean(axis=0) @ ax1,
             X_cent[conditions[c]].mean(axis=0) @ ax2, c=colors[c], lw=3)    
    plt.plot(X_cent[conditions[c]].mean(axis=0)[0] @ ax1, 
             X_cent[conditions[c]].mean(axis=0)[0] @ ax2, 
             marker='o', c=colors[c], lw=3)
    plt.plot(traj_tot[conditions[c]].mean(axis=0) @ ax1, 
             traj_tot[conditions[c]].mean(axis=0) @ ax2, 
             c=colors[c], ls='dotted', lw=3)
    plt.plot(traj_tot[conditions[c]].mean(axis=0)[0] @ ax1, 
             traj_tot[conditions[c]].mean(axis=0)[0] @ ax2, 
             marker='o', c=colors[c], ls='dotted', lw=3)
    plt.scatter(traj_tot[conditions[c]].mean(axis=0)[mante.ctx_only_pre_duration_discrete] @ ax1,
                traj_tot[conditions[c]].mean(axis=0)[mante.ctx_only_pre_duration_discrete] @ ax2,
                color=colors[c], marker='^', s=100)
plt.xlabel('$m$')
plt.ylabel('$I_{color}$')
plt.xticks([])
plt.yticks([])
plt.savefig('../figures/neurips/proj4.pdf', bbox_inches='tight')


cmap = matplotlib.cm.get_cmap('PiYG')

conditions = [((choice == i) & (context == j)) for i in (-1, 1) for j in (-1, 1)]
colors = ['peru', 'firebrick', 'peru', 'firebrick']

ax1 = m
ax2 = wis[2]

for c in range(len(conditions)):
    plt.plot(X_cent[conditions[c]].mean(axis=0) @ ax1,
             X_cent[conditions[c]].mean(axis=0) @ ax2, c=colors[c], lw=3)    
    plt.plot(X_cent[conditions[c]].mean(axis=0)[0] @ ax1, 
             X_cent[conditions[c]].mean(axis=0)[0] @ ax2, 
             marker='o', c=colors[c], lw=3)
    plt.plot(traj_tot[conditions[c]].mean(axis=0) @ ax1, 
             traj_tot[conditions[c]].mean(axis=0) @ ax2, 
             c=colors[c], ls='dotted', lw=3)
    plt.plot(traj_tot[conditions[c]].mean(axis=0)[0] @ ax1, 
             traj_tot[conditions[c]].mean(axis=0)[0] @ ax2, 
             marker='o', c=colors[c], ls='dotted', lw=3)
    plt.scatter(traj_tot[conditions[c]].mean(axis=0)[mante.ctx_only_pre_duration_discrete] @ ax1,
                traj_tot[conditions[c]].mean(axis=0)[mante.ctx_only_pre_duration_discrete] @ ax2,
                color=colors[c], marker='^', s=100)
plt.xlabel('$m$')
plt.ylabel('$I_{ctx1}$')
plt.xticks([])
plt.yticks([])


z, model = clustering.gmm_fit(wis+ms+ns, 2, algo='bayes', random_state=2022)


vecs = wis + ms + ns
i1, i2, ic1, ic2 = wis
n = ns[0]
m = ms[0]


# np.save('../data/mante_monkeyA_z_15.npy', z)


plt.scatter(wis[2], wis[3])
plt.scatter(wis[2][idx_bad], wis[3][idx_bad])


set(idx_bad).intersection(set(np.where(z==1)[0]))


get_ipython().run_line_magic("matplotlib", " inline")
data_plot = pd.DataFrame(np.stack(vecs + [z]).T, columns = ['i1', 'i2', 'ic1', 'ic2', 'm', 'n', 'z'])
sns.pairplot(data_plot, hue='z')
plt.savefig('../figures/neurips/distr_monkeyA.pdf', bbox_inches='tight')


kurtosis(np.array(vecs).T)


get_ipython().run_line_magic("matplotlib", " inline")
fig, ax = plt.subplots(figsize=(10, 10))
reorder = np.argsort(z)
ax.matshow(np.outer(m, n)[reorder][:, reorder], cmap='coolwarm')
#plt.colorbar(ax=ax)


_, counts = np.unique(z, return_counts=True)
print(counts)
plt.bar([0, 1], counts, color=['tab:blue', 'tab:orange'])


# Are poorly fitted neurons irrelevant ?
r2s = np.array(stats.r2_idneurons(X_cent, traj, return_all=True))
sns.scatterplot(X_mean[z==0], r2s[z==0], color='tab:blue')
sns.scatterplot(X_mean[z==1], r2s[z==1], color='tab:orange')
plt.ylim(-1, 1)
plt.axhline(0, c='gray', ls='--')
plt.axhline(1, c='gray', ls='--')
plt.xlabel('Mean FR')
plt.ylabel('R2')
plt.savefig('../figures/neurips/distr_r2mA.pdf', bbox_inches='tight')


vecs = wis + ms + ns
vsn = np.stack(vecs)
print(vsn.shape)
norms = np.linalg.norm(vsn, axis=0)
plt.scatter(norms[z==0], r2s[z==0], c='tab:blue')
plt.scatter(norms[z==1], r2s[z==1], c='tab:orange')
plt.xlabel('norm')
plt.ylabel('r2')
plt.axhline(0, ls='--', c='gray')
plt.axhline(1, ls='--', c='gray')
plt.ylim(-1, 1)


# Lets' inactivate the population 0, the one that should be doing nothing
net_tmp = net_behav.clone()
with torch.no_grad():
    net_tmp.wi[:, z==0] = 0
    net_tmp.m[z==0] = 0
    net_tmp.n[z==0] = 0
loss, acc = mante.test_mante(net_tmp, inputs, targets_task, mask_task)
print(acc)
# train(net_tmp, inputs, targets_task, mask_task, 30, lr=5e-1, keep_best=True)  # training the readout only


outp, traj = net_tmp(inputs, return_dynamics=True)
outp = outp.detach()
loss = loss_mse(outp, targets_task, mask_task)
acc = mante.accuracy_mante(targets_task, outp)
print(loss)
print(acc)


mante.psychometric_matrices(net_tmp, coherences=coherences)


# And inactivating population 1:
net_tmp = net_behav.clone()
with torch.no_grad():
    net_tmp.wi[:, z==1] = 0
    net_tmp.m[z==1] = 0
    net_tmp.n[z==1] = 0
loss, acc = mante.test_mante(net_tmp, inputs, targets_task, mask_task)
print(acc)


mante.psychometric_matrices(net_tmp, coherences=coherences)


nk = np.where(z==0)[0]  # neurons_kept


cmap = matplotlib.cm.get_cmap('bwr')

conditions = [((direction == 0) & (context == 1)),
              ((direction == 5) & (context == 1))]
colors = [cmap(0), cmap(256)]

ax1 = beta_choice
ax2 = beta_motion

for c in range(len(conditions)):
    plt.plot(X_cent[conditions[c]][:, :, nk].mean(axis=0) @ ax1[nk], 
             X_cent[conditions[c]][:, :, nk].mean(axis=0) @ ax2[nk], c=colors[c], lw=3)    
    plt.plot(X_cent[conditions[c]][:, :, nk].mean(axis=0)[0] @ ax1[nk], 
             X_cent[conditions[c]][:, :, nk].mean(axis=0)[0] @ ax2[nk], 
             marker='o', c=colors[c], lw=3)
    plt.plot(traj_tot[conditions[c]][:, :, nk].mean(axis=0) @ ax1[nk], 
             traj_tot[conditions[c]][:, :, nk].mean(axis=0) @ ax2[nk], 
             c=colors[c], ls='dotted', lw=3)
    plt.plot(traj_tot[conditions[c]][:, :, nk].mean(axis=0)[0] @ ax1[nk], 
             traj_tot[conditions[c]][:, :, nk].mean(axis=0)[0] @ ax2[nk], 
             marker='o', c=colors[c], ls='dotted', lw=3)
    plt.scatter(traj_tot[conditions[c]][:, :, nk].mean(axis=0)[mante.ctx_only_pre_duration_discrete] @ ax1[nk],
                traj_tot[conditions[c]][:, :, nk].mean(axis=0)[mante.ctx_only_pre_duration_discrete] @ ax2[nk],
                color=colors[c], marker='^', s=100)
plt.xlabel('choice axis')
plt.ylabel('motion axis')
plt.xticks([])
plt.yticks([])


cmap = matplotlib.cm.get_cmap('PiYG')

conditions = [((color == i) & (context == -1)) for i in (0, 5)]
colors = [cmap(0), cmap(256)]

ax1 = beta_choice[nk]
ax2 = beta_color[nk]

for c in range(len(conditions)):
    plt.plot(X_cent[conditions[c]][:, :, nk].mean(axis=0) @ ax1,
             X_cent[conditions[c]][:, :, nk].mean(axis=0) @ ax2, c=colors[c], lw=3)    
    plt.plot(X_cent[conditions[c]][:, :, nk].mean(axis=0)[0] @ ax1, 
             X_cent[conditions[c]][:, :, nk].mean(axis=0)[0] @ ax2, 
             marker='o', c=colors[c], lw=3)
    plt.plot(traj_tot[conditions[c]][:, :, nk].mean(axis=0) @ ax1, 
             traj_tot[conditions[c]][:, :, nk].mean(axis=0) @ ax2, 
             c=colors[c], ls='dotted', lw=3)
    plt.plot(traj_tot[conditions[c]][:, :, nk].mean(axis=0)[0] @ ax1, 
             traj_tot[conditions[c]][:, :, nk].mean(axis=0)[0] @ ax2, 
             marker='o', c=colors[c], ls='dotted', lw=3)
    plt.scatter(traj_tot[conditions[c]][:, :, nk].mean(axis=0)[mante.ctx_only_pre_duration_discrete] @ ax1,
                traj_tot[conditions[c]][:, :, nk].mean(axis=0)[mante.ctx_only_pre_duration_discrete] @ ax2,
                color=colors[c], marker='^', s=100)
plt.xlabel('choice axis')
plt.ylabel('color axis')
plt.xticks([])
plt.yticks([])


remap_neurons = np.where(z!=0)[0]


_, counts = np.unique(z, return_counts=True)
new_size = counts[1]
net_tmp = LowRankRNN(4, new_size, 1, 0, 0.2, rank=1, output_non_linearity=(lambda x: x), 
                     wi_init=net.wi_full[:, z!=0], 
                     m_init=net.m[z!=0] * sqrt(new_size) / sqrt(size), 
                     n_init=net.n[z!=0] * sqrt(new_size) / sqrt(size), 
                     wo_init=torch.from_numpy(-beta_choice.reshape((-1, 1))[z!=0]),
                     train_wi=False, train_wrec=False, train_si=False, train_wo=True)

train(net_tmp, inputs, targets_task, mask_task, 30, lr=1e-1, keep_best=True)


outp, traj = net_tmp(inputs, return_dynamics=True)
outp = outp.detach()
loss = loss_mse(outp, targets_task, mask_task)
acc = mante.accuracy_mante(targets_task, outp)
print(loss)
print(acc)

traj = traj.detach().numpy()


stats.r2_score(X_cent[:, :, remap_neurons].ravel(), traj[:, mante.ctx_only_pre_duration_discrete+1:, :].ravel())


m = net_tmp.m.detach().numpy().squeeze()
n = net_tmp.n.detach().numpy().squeeze()
wi1 = net_tmp.wi_full[0].detach().numpy()
wi2 = net_tmp.wi_full[1].detach().numpy()
wic1 = net_tmp.wi_full[2].detach().numpy()
wic2 = net_tmp.wi_full[3].detach().numpy()
wo = net_tmp.wo_full.detach().numpy().squeeze()
vecs = [wi1, wi2, wic1, wic2, n, m, wo]


mante.psychometric_matrices(net_tmp, coherences=coherences)


# z, model = clustering.gmm_fit([wi1, wi2, m, n], 4, algo='bayes')
# z = np.abs(wi1) > np.abs(wi2)
z = np.abs(wic1) > np.abs(wic2)


# Most important neurons ? (classified by norm on connectivity space)
vsn = np.array(vecs)
norms = np.linalg.norm(vsn, axis=0)
idxes = np.argsort(norms)[::-1]


losses = []
accs = []
for i in idxes:
    net2 = net_tmp.clone()
    # p = 3
    with torch.no_grad():
        net2.wi[:, i] = 0
        net2.m[i] = 0
        net2.n[i] = 0
    outp = net2(inputs)
    outp = outp.detach()
    loss = loss_mse(outp, targets_task, mask_task)
    acc = mante.accuracy_mante(targets_task, outp)
    losses.append(loss)
    accs.append(acc)
plt.plot(accs)


imp_neurons = idxes[np.where(np.array(accs) < 0.90)[0]]
print(imp_neurons)
neurons_rm = remap_neurons[imp_neurons]
print(neurons_rm)
print(len(neurons_rm))


set(neurons_rm).intersection(set(idx_bad))


sns.scatterplot(X_mean, r2s)
plt.scatter(X_mean[neurons_rm], r2s[neurons_rm], marker='^', c='red', s=45)
plt.ylim(-1, 1)
plt.axhline(0, c='gray', ls='--')
plt.axhline(1, c='gray', ls='--')
plt.xlabel('Mean FR')
plt.ylabel('R2')


plt.scatter(wi1, wi2)
neurons = [41]
plt.scatter(wi1[imp_neurons], wi2[imp_neurons], marker='^', s=70, c='red')
plt.xlabel('I_motion')
plt.ylabel('I_color')


plt.scatter(wi1, n)
plt.scatter(wi1[imp_neurons], n[imp_neurons], marker='^', s=70, c='red')
plt.xlabel('I motion')
plt.ylabel('n')


plt.scatter(wi2, n)
plt.scatter(wi2[imp_neurons], n[imp_neurons], marker='^', s=70, c='red')
plt.xlabel('I color')
plt.ylabel('n')


plt.scatter(wic1, wic2)
plt.scatter(wic1[imp_neurons], wic2[imp_neurons], marker='^', s=70, c='red')
plt.xlabel('I ctx 1')
plt.ylabel('I ctx 2')


plt.scatter(beta_choice, beta_context)
plt.scatter(beta_choice[neurons_rm], beta_context[neurons_rm], marker='^', s=70, c='red')
plt.xlabel('beta_choice')
plt.ylabel('beta_context')


plt.scatter(beta_motion, beta_color)
plt.scatter(beta_motion[neurons_rm], beta_color[neurons_rm], marker='^', s=70, c='red')
plt.xlabel('beta_motion')
plt.ylabel('beta_color')


imp_neurons


neurons_rm


top_neurons = imp_neurons[:4]
top_neurons_rm = neurons_rm[:4]


plt.scatter(wic1, wic2)
plt.scatter(wic1[146], wic2[146], marker='^', s=70, c='red')
plt.xlabel('I ctx 1')
plt.ylabel('I ctx 2')


r2s[698]


net4 = net_behav.clone()

torm = [346, 314, 698]
with torch.no_grad():
    net4.wi[:, torm] = 0
    net4.m[torm] = 0
    net4.n[torm] = 0
    #net4.wo[others] = 0
train(net4, inputs, targets_task, mask_task, 20, 1, keep_best=True)


outp, traj4 = net4(inputs, return_dynamics=True)
outp = outp.detach()
loss = loss_mse(outp, targets_task, mask_task)
acc = mante.accuracy_mante(targets_task, outp)
print(loss)
print(acc)


mante.psychometric_matrices(net4, coherences=coherences)


wr = np.outer(net4.m.squeeze().detach().numpy(), net4.n.squeeze().detach().numpy())
print(np.sum(wr != 0))
plt.matshow(wr[neurons_rm][:, neurons_rm])
plt.colorbar()


_, traj = net(inputs, return_dynamics=True)
traj = traj.detach().numpy()


traj.shape


i = 212
for k in conditions_rsample:
    pl, = plt.plot(X_cent[k, :, i])
    plt.plot(traj[k, mante.ctx_only_pre_duration_discrete:, i], ls='-.', c=pl.get_color())
plt.title(f'neuron #{i}')
plt.xlabel('time')
plt.ylabel('x')


i = 680
for k in conditions_rsample:
    pl, = plt.plot(X_cent[k, :, i])
    plt.plot(traj[k, mante.ctx_only_pre_duration_discrete:, i], ls='-.', c=pl.get_color())
plt.title(f'neuron #{i}')
plt.xlabel('time')
plt.ylabel('x')


i = 5
for k in conditions_rsample:
    pl, = plt.plot(X_cent[k, :, i])
    plt.plot(traj[k, mante.ctx_only_pre_duration_discrete:, i], ls='-.', c=pl.get_color())
plt.title(f'neuron #{i}')
plt.xlabel('time')
plt.ylabel('x')


i = 346
for k in conditions_rsample:
    pl, = plt.plot(X_cent[k, :, i])
    plt.plot(traj[k, mante.ctx_only_pre_duration_discrete:, i], ls='-.', c=pl.get_color())
plt.title(f'neuron #{i}')
plt.xlabel('time')
plt.ylabel('x')


i = 318
for k in conditions_rsample:
    pl, = plt.plot(X_cent[k, :, i])
    plt.plot(traj[k, mante.ctx_only_pre_duration_discrete:, i], ls='-.', c=pl.get_color())
plt.title(f'neuron #{i}')
plt.xlabel('time')
plt.ylabel('x')


i = 698
for k in conditions_rsample:
    pl, = plt.plot(X_cent[k, :, i])
    plt.plot(traj[k, mante.ctx_only_pre_duration_discrete:, i], ls='-.', c=pl.get_color())
plt.title(f'neuron #{i}')
plt.xlabel('time')
plt.ylabel('x')



